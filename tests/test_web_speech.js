const { chromium } = require('playwright');

async function testWebSpeechAPI() {
  console.log('ğŸ¤ AIVlingual Web Speech API Test');
  
  const browser = await chromium.launch({ 
    headless: false,
    args: [
      '--use-fake-device-for-media-stream',
      '--use-fake-ui-for-media-stream',
      '--allow-file-access',
      '--enable-features=WebSpeechAPI'
    ]
  });
  
  const context = await browser.newContext({
    permissions: ['microphone'],
    locale: 'ja-JP'
  });
  
  const page = await context.newPage();

  // ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ç›£è¦–
  page.on('console', msg => {
    if (msg.text().includes('speech') || msg.text().includes('Speech')) {
      console.log(`ğŸ“¢ Console: ${msg.text()}`);
    }
  });

  try {
    // ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é–‹ã
    await page.goto('http://localhost:3002/', { waitUntil: 'networkidle' });
    console.log('âœ… Application loaded');

    // Web Speech APIã®ã‚µãƒãƒ¼ãƒˆçŠ¶æ³ã‚’ç¢ºèª
    const speechSupport = await page.evaluate(() => {
      const recognition = 'webkitSpeechRecognition' in window || 'SpeechRecognition' in window;
      const synthesis = 'speechSynthesis' in window;
      
      // åˆ©ç”¨å¯èƒ½ãªéŸ³å£°ã‚’å–å¾—
      let voices = [];
      if (synthesis) {
        voices = window.speechSynthesis.getVoices();
        // éŸ³å£°ãƒªã‚¹ãƒˆãŒéåŒæœŸã§èª­ã¿è¾¼ã¾ã‚Œã‚‹å ´åˆãŒã‚ã‚‹ãŸã‚ã€å†åº¦å–å¾—
        window.speechSynthesis.onvoiceschanged = () => {
          voices = window.speechSynthesis.getVoices();
        };
      }
      
      return {
        recognition,
        synthesis,
        voiceCount: voices.length,
        japaneseVoices: voices.filter(v => v.lang.includes('ja')).length,
        englishVoices: voices.filter(v => v.lang.includes('en')).length
      };
    });

    console.log('\nğŸ“Š Web Speech API Support:');
    console.log(`   Speech Recognition: ${speechSupport.recognition ? 'âœ… Supported' : 'âŒ Not supported'}`);
    console.log(`   Speech Synthesis: ${speechSupport.synthesis ? 'âœ… Supported' : 'âŒ Not supported'}`);
    console.log(`   Total voices: ${speechSupport.voiceCount}`);
    console.log(`   Japanese voices: ${speechSupport.japaneseVoices}`);
    console.log(`   English voices: ${speechSupport.englishVoices}`);

    // Web Speechèªè­˜ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’æ¢ã™
    console.log('\nğŸ” Looking for speech recognition interface...');
    
    // ãƒã‚¤ã‚¯ãƒœã‚¿ãƒ³ã¾ãŸã¯éŸ³å£°å…¥åŠ›ãƒœã‚¿ãƒ³ã‚’æ¢ã™
    const micButton = await page.$('button[aria-label*="mic"], button[aria-label*="éŸ³å£°"], button:has-text("ğŸ¤"), [class*="mic"], [class*="voice"]');
    
    if (micButton) {
      console.log('âœ… Found microphone button');
      
      // ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ
      await page.screenshot({ 
        path: 'test-screenshots/speech-before-click.png' 
      });
      
      // ãƒã‚¤ã‚¯ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
      await micButton.click();
      console.log('âœ… Clicked microphone button');
      
      // è¨±å¯ãƒ€ã‚¤ã‚¢ãƒ­ã‚°ã‚„ã‚¹ãƒ†ãƒ¼ãƒˆå¤‰æ›´ã‚’å¾…ã¤
      await page.waitForTimeout(2000);
      
      // ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å¤‰æ›´ã‚’ç¢ºèª
      const isRecording = await page.evaluate(() => {
        // éŒ²éŸ³ä¸­ã‚’ç¤ºã™è¦ç´ ã‚’æ¢ã™
        const recordingIndicators = document.querySelectorAll('[class*="recording"], [class*="listening"], [class*="active"]');
        return recordingIndicators.length > 0;
      });
      
      console.log(`âœ… Recording status: ${isRecording ? 'Active' : 'Inactive'}`);
      
      if (isRecording) {
        await page.screenshot({ 
          path: 'test-screenshots/speech-recording.png' 
        });
      }
      
      // Web Speech APIã‚’ç›´æ¥ãƒ†ã‚¹ãƒˆ
      console.log('\nğŸ§ª Testing Web Speech API directly...');
      
      const speechTest = await page.evaluate(() => {
        return new Promise((resolve) => {
          const results = {
            recognitionCreated: false,
            recognitionStarted: false,
            recognitionError: null,
            recognitionResult: null
          };
          
          try {
            const SpeechRecognition = window.webkitSpeechRecognition || window.SpeechRecognition;
            if (!SpeechRecognition) {
              resolve({ ...results, recognitionError: 'API not available' });
              return;
            }
            
            const recognition = new SpeechRecognition();
            results.recognitionCreated = true;
            
            // è¨­å®š
            recognition.continuous = false;
            recognition.interimResults = true;
            recognition.lang = 'ja-JP';
            
            // ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©ãƒ¼
            recognition.onstart = () => {
              results.recognitionStarted = true;
            };
            
            recognition.onerror = (event) => {
              results.recognitionError = event.error;
              resolve(results);
            };
            
            recognition.onresult = (event) => {
              const result = event.results[0];
              results.recognitionResult = {
                transcript: result[0].transcript,
                confidence: result[0].confidence,
                isFinal: result.isFinal
              };
            };
            
            recognition.onend = () => {
              resolve(results);
            };
            
            // èªè­˜é–‹å§‹
            recognition.start();
            
            // ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®š
            setTimeout(() => {
              recognition.stop();
              resolve(results);
            }, 5000);
            
          } catch (error) {
            results.recognitionError = error.message;
            resolve(results);
          }
        });
      });
      
      console.log('\nğŸ“Š Speech Recognition Test Results:');
      console.log(`   Recognition created: ${speechTest.recognitionCreated ? 'âœ…' : 'âŒ'}`);
      console.log(`   Recognition started: ${speechTest.recognitionStarted ? 'âœ…' : 'âŒ'}`);
      if (speechTest.recognitionError) {
        console.log(`   Error: ${speechTest.recognitionError}`);
      }
      if (speechTest.recognitionResult) {
        console.log(`   Result: "${speechTest.recognitionResult.transcript}"`);
        console.log(`   Confidence: ${speechTest.recognitionResult.confidence}`);
      }
      
    } else {
      console.log('âš ï¸ Microphone button not found');
      console.log('   The application might not have speech recognition UI implemented yet');
    }

    // Speech Synthesisï¼ˆéŸ³å£°åˆæˆï¼‰ã®ãƒ†ã‚¹ãƒˆ
    console.log('\nğŸ”Š Testing Speech Synthesis...');
    
    const synthTest = await page.evaluate(() => {
      return new Promise((resolve) => {
        if (!window.speechSynthesis) {
          resolve({ supported: false });
          return;
        }
        
        const utterance = new SpeechSynthesisUtterance('ã“ã‚“ã«ã¡ã¯ã€AIVlingualã§ã™ã€‚');
        utterance.lang = 'ja-JP';
        utterance.rate = 1.0;
        utterance.pitch = 1.0;
        utterance.volume = 0.5;
        
        let speaking = false;
        utterance.onstart = () => { speaking = true; };
        utterance.onend = () => {
          resolve({
            supported: true,
            speaking: speaking,
            voices: window.speechSynthesis.getVoices().length
          });
        };
        utterance.onerror = (e) => {
          resolve({
            supported: true,
            error: e.error
          });
        };
        
        window.speechSynthesis.speak(utterance);
        
        // ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
        setTimeout(() => {
          window.speechSynthesis.cancel();
          resolve({
            supported: true,
            timeout: true
          });
        }, 5000);
      });
    });
    
    console.log('ğŸ“Š Speech Synthesis Test Results:');
    console.log(`   Supported: ${synthTest.supported ? 'âœ…' : 'âŒ'}`);
    if (synthTest.error) {
      console.log(`   Error: ${synthTest.error}`);
    } else if (synthTest.timeout) {
      console.log(`   Status: Timeout (synthesis might be disabled)`);
    } else if (synthTest.speaking) {
      console.log(`   Status: Successfully spoke Japanese text`);
    }

    // æœ€çµ‚ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ
    await page.screenshot({ 
      path: 'test-screenshots/speech-final.png',
      fullPage: true 
    });

    console.log('\nâœ… Web Speech API tests completed!');

  } catch (error) {
    console.error('âŒ Test failed:', error);
    await page.screenshot({ 
      path: 'test-screenshots/speech-error.png',
      fullPage: true 
    });
  } finally {
    await browser.close();
  }
}

// ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆä¿å­˜ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
const fs = require('fs');
if (!fs.existsSync('test-screenshots')) {
  fs.mkdirSync('test-screenshots');
}

// ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
testWebSpeechAPI().catch(console.error);
#!/usr/bin/env python3
"""
å®Ÿéš›ã®Vtuberå‹•ç”»ã§ã®ãƒ†ã‚¹ãƒˆ
å‹•ç”»URL: https://youtu.be/fH52x36P-L4
"""

import asyncio
import sys
from pathlib import Path
import json

# Add parent directory to path
sys.path.append(str(Path(__file__).parent.parent / "backend"))

from app.services.youtube_service import YouTubeService
from app.services.vocabulary_extractor import VocabularyExtractor
from app.services.database_service import db_service

async def test_vtuber_video():
    """å®Ÿéš›ã®Vtuberå‹•ç”»ã§ãƒ†ã‚¹ãƒˆ"""
    print("=" * 60)
    print("AIVlingual - Vtuberå‹•ç”»è§£æãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    
    # ãƒ†ã‚¹ãƒˆå‹•ç”»ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼æä¾›ã®Vtuberå‹•ç”»ï¼‰
    video_url = "https://youtu.be/knbMyna6DGs?si=L4hloZ-fwh0qWBfq"
    print(f"\nğŸ¬ ãƒ†ã‚¹ãƒˆå‹•ç”»: {video_url}")
    
    # ã‚µãƒ¼ãƒ“ã‚¹ã®åˆæœŸåŒ–
    youtube_service = YouTubeService()
    vocabulary_extractor = VocabularyExtractor()
    
    # 1. å‹•ç”»æƒ…å ±ã®å–å¾—
    print("\n1ï¸âƒ£ å‹•ç”»æƒ…å ±ã‚’å–å¾—ä¸­...")
    video_id = youtube_service.extract_video_id(video_url)
    print(f"   Video ID: {video_id}")
    
    video_info = await youtube_service.get_video_info(video_id)
    if video_info:
        print(f"   âœ… ã‚¿ã‚¤ãƒˆãƒ«: {video_info.get('title', 'N/A')}")
        print(f"   ãƒãƒ£ãƒ³ãƒãƒ«: {video_info.get('channel_title', 'N/A')}")
        print(f"   å†ç”Ÿæ™‚é–“: {video_info.get('duration', 0)}ç§’")
        print(f"   è¦–è´å›æ•°: {video_info.get('view_count', 0):,}")
        print(f"   ã„ã„ã­æ•°: {video_info.get('like_count', 0):,}")
        
        # ã‚¿ã‚°ãŒã‚ã‚Œã°è¡¨ç¤º
        tags = video_info.get('tags', [])
        if tags:
            print(f"   ã‚¿ã‚°: {', '.join(tags[:5])}")
    else:
        print("   âŒ å‹•ç”»æƒ…å ±ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
        return
    
    # 2. å­—å¹•ï¼ˆãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼‰ã®å–å¾—
    print("\n2ï¸âƒ£ å­—å¹•ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
    transcript = await youtube_service.get_transcript(video_id)
    if transcript:
        print(f"   âœ… {len(transcript)}å€‹ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’å–å¾—")
        
        # æœ€åˆã®5ã¤ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’è¡¨ç¤º
        print("\n   å­—å¹•ã‚µãƒ³ãƒ—ãƒ«:")
        for i, segment in enumerate(transcript[:5]):
            text = segment['text']
            start = segment['start']
            print(f"   [{start:.1f}s] {text}")
    else:
        print("   âŒ å­—å¹•ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
        return
    
    # 3. èªå½™ã®æŠ½å‡º
    print("\n3ï¸âƒ£ èªå½™ã‚’æŠ½å‡ºä¸­...")
    result = await vocabulary_extractor.extract_from_video(video_url)
    
    if "error" not in result:
        vocab_count = result.get('vocabulary_extracted', 0)
        print(f"   âœ… {vocab_count}å€‹ã®èªå½™ã‚’æŠ½å‡ºã—ã¾ã—ãŸ")
        
        # æŠ½å‡ºã•ã‚ŒãŸèªå½™ã‚’è¡¨ç¤º
        vocab_items = result.get('vocabulary_items', [])
        if vocab_items:
            print("\n   æŠ½å‡ºã•ã‚ŒãŸèªå½™ã‚µãƒ³ãƒ—ãƒ«:")
            for item in vocab_items[:10]:  # æœ€åˆã®10å€‹
                japanese = item.get('japanese_text', '')
                english = item.get('english_text', '')
                difficulty = item.get('difficulty_level', 'N/A')
                context = item.get('context', '')[:50] + '...' if item.get('context') else ''
                
                print(f"\n   ğŸ“ {japanese}")
                print(f"      è‹±è¨³: {english}")
                print(f"      é›£æ˜“åº¦: N{difficulty}")
                print(f"      æ–‡è„ˆ: {context}")
        
        # è¨€èªçµ±è¨ˆ
        lang_stats = result.get('language_stats', {})
        if lang_stats:
            print("\n   è¨€èªçµ±è¨ˆ:")
            print(f"   - æ—¥æœ¬èªã‚»ã‚°ãƒ¡ãƒ³ãƒˆ: {lang_stats.get('japanese_segments', 0)}")
            print(f"   - è‹±èªã‚»ã‚°ãƒ¡ãƒ³ãƒˆ: {lang_stats.get('english_segments', 0)}")
            print(f"   - æ··åœ¨ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ: {lang_stats.get('mixed_segments', 0)}")
    else:
        print(f"   âŒ èªå½™æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {result['error']}")
    
    # 4. ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ™ãƒ¼ã‚¹ã®è¡¨ç¾æ¤œå‡º
    print("\n4ï¸âƒ£ Vtuberã‚¹ãƒ©ãƒ³ã‚°ãƒ»è¡¨ç¾ã‚’æ¤œå‡ºä¸­...")
    
    # ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆå…¨ä½“ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’çµåˆ
    full_text = " ".join([seg['text'] for seg in transcript]) if transcript else ""
    
    if full_text:
        expressions = youtube_service._extract_expressions_from_transcript(transcript)
        
        if expressions:
            print(f"   âœ… {len(expressions)}å€‹ã®è¡¨ç¾ã‚’æ¤œå‡º")
            
            # è¡¨ç¾ã‚¿ã‚¤ãƒ—åˆ¥ã«é›†è¨ˆ
            type_counts = {}
            for expr in expressions:
                expr_type = expr.get('type', 'unknown')
                type_counts[expr_type] = type_counts.get(expr_type, 0) + 1
            
            print("\n   è¡¨ç¾ã‚¿ã‚¤ãƒ—åˆ¥é›†è¨ˆ:")
            for expr_type, count in type_counts.items():
                print(f"   - {expr_type}: {count}å€‹")
            
            # ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
            print("\n   æ¤œå‡ºã•ã‚ŒãŸè¡¨ç¾ã‚µãƒ³ãƒ—ãƒ«:")
            for expr in expressions[:10]:
                japanese = expr.get('japanese', '')
                english = expr.get('english', '')
                expr_type = expr.get('type', '')
                timestamp = expr.get('timestamp', 0)
                
                print(f"   [{timestamp:.1f}s] {japanese} â†’ {english} ({expr_type})")
    
    print("\n" + "=" * 60)
    print("ãƒ†ã‚¹ãƒˆå®Œäº†ï¼")
    print("=" * 60)

async def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–
    await db_service.init_db()
    
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    await test_vtuber_video()

if __name__ == "__main__":
    asyncio.run(main())
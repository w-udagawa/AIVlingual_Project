#!/usr/bin/env python
"""
ã‚·ãƒ³ãƒ—ãƒ«ãªYouTubeãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
æœ€å°é™ã®ã‚³ãƒ¼ãƒ‰ã§å‹•ä½œç¢ºèª
"""
import asyncio
import sys
import re
import argparse
sys.path.append('.')

from youtube_transcript_api import YouTubeTranscriptApi
from app.services.nlp_vocabulary_extractor import nlp_extractor
from working_video_ids import get_test_video, WORKING_VIDEO_IDS

def detect_language_ratio(text):
    """ãƒ†ã‚­ã‚¹ãƒˆã®è¨€èªæ¯”ç‡ã‚’æ¤œå‡º"""
    # æ—¥æœ¬èªæ–‡å­—ï¼ˆã²ã‚‰ãŒãªã€ã‚«ã‚¿ã‚«ãƒŠã€æ¼¢å­—ï¼‰
    japanese_chars = len(re.findall(r'[\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FAF]', text))
    # è‹±èªæ–‡å­—ï¼ˆã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆï¼‰
    english_chars = len(re.findall(r'[a-zA-Z]', text))
    
    total_chars = japanese_chars + english_chars
    if total_chars == 0:
        return 'unknown', 0, 0
    
    ja_ratio = japanese_chars / total_chars
    en_ratio = english_chars / total_chars
    
    # 70%ä»¥ä¸Šã‚’å ã‚ã‚‹è¨€èªã‚’ä¸»è¨€èªã¨ã™ã‚‹
    if ja_ratio >= 0.7:
        return 'japanese', ja_ratio, en_ratio
    elif en_ratio >= 0.7:
        return 'english', ja_ratio, en_ratio
    else:
        return 'mixed', ja_ratio, en_ratio

def test_youtube_direct(video_id, force_lang=None):
    """youtube-transcript-apiã‚’ç›´æ¥ä½¿ç”¨ã—ã¦ãƒ†ã‚¹ãƒˆ"""
    print(f"\nå‹•ç”»ID: {video_id}")
    print("-" * 40)
    
    try:
        # å­—å¹•ãƒªã‚¹ãƒˆã‚’å–å¾—
        transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)
        
        print("åˆ©ç”¨å¯èƒ½ãªå­—å¹•:")
        available_langs = []
        for transcript in transcript_list:
            print(f"  - {transcript.language_code} ({transcript.language})")
            available_langs.append(transcript.language_code)
        
        # è¨€èªã‚’æ±ºå®š
        if force_lang:
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šã®è¨€èª
            target_lang = force_lang
            print(f"\nãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šè¨€èª: {target_lang}")
        else:
            # è‡ªå‹•é¸æŠ
            if 'ja' in available_langs:
                target_lang = 'ja'
            elif 'en' in available_langs:
                target_lang = 'en'
            else:
                target_lang = available_langs[0] if available_langs else None
            print(f"\nè‡ªå‹•é¸æŠè¨€èª: {target_lang}")
        
        # å­—å¹•ã‚’å–å¾—
        if target_lang:
            transcript_data = YouTubeTranscriptApi.get_transcript(video_id, languages=[target_lang])
        else:
            transcript_data = YouTubeTranscriptApi.get_transcript(video_id)
            
        print(f"âœ… å­—å¹•å–å¾—æˆåŠŸ: {len(transcript_data)}ã‚¨ãƒ³ãƒˆãƒª")
        
        # è¨€èªåˆ†æï¼ˆæœ€åˆã®30ã‚¨ãƒ³ãƒˆãƒªï¼‰
        sample_text = " ".join([entry['text'] for entry in transcript_data[:30]])
        detected_lang, ja_ratio, en_ratio = detect_language_ratio(sample_text)
        
        print(f"\nè¨€èªåˆ†æçµæœ:")
        print(f"  æ—¥æœ¬èª: {ja_ratio:.1%}")
        print(f"  è‹±èª: {en_ratio:.1%}")
        print(f"  åˆ¤å®š: {detected_lang}")
        
        # æœ€åˆã®3ã¤ã‚’è¡¨ç¤º
        print("\nã‚µãƒ³ãƒ—ãƒ«:")
        for i, entry in enumerate(transcript_data[:3]):
            print(f"  [{entry['start']:.1f}s] {entry['text']}")
        
        return True, transcript_data, detected_lang
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {str(e)}")
        return False, None, None

async def test_nlp_extraction(transcript_data, detected_lang):
    """NLPèªå½™æŠ½å‡ºã‚’ãƒ†ã‚¹ãƒˆ"""
    if not transcript_data:
        return
    
    print("\nNLPèªå½™æŠ½å‡ºãƒ†ã‚¹ãƒˆ")
    print("-" * 40)
    
    # ãƒ†ã‚­ã‚¹ãƒˆã‚’çµåˆï¼ˆæœ€åˆã®1000æ–‡å­—ï¼‰
    text = " ".join([entry['text'] for entry in transcript_data])[:1000]
    print(f"ãƒ†ã‚­ã‚¹ãƒˆé•·: {len(text)}æ–‡å­—")
    
    # æ¤œå‡ºã•ã‚ŒãŸè¨€èªã«åŸºã¥ã„ã¦NLPæŠ½å‡º
    if detected_lang == 'japanese':
        print("æ—¥æœ¬èªãƒ¢ãƒ¼ãƒ‰ã§æŠ½å‡º...")
        vocabulary = await nlp_extractor.extract_from_text_nlp(text, 'japanese')
    elif detected_lang == 'english':
        print("è‹±èªãƒ¢ãƒ¼ãƒ‰ã§æŠ½å‡º...")
        vocabulary = await nlp_extractor.extract_from_text_nlp(text, 'english')
    else:
        print("æ··åœ¨ãƒ¢ãƒ¼ãƒ‰ã§æŠ½å‡ºï¼ˆä¸¡è¨€èªï¼‰...")
        # æ—¥æœ¬èªã¨è‹±èªã®ä¸¡æ–¹ã§æŠ½å‡º
        ja_vocab = await nlp_extractor.extract_from_text_nlp(text, 'japanese')
        en_vocab = await nlp_extractor.extract_from_text_nlp(text, 'english')
        vocabulary = ja_vocab + en_vocab
        print(f"  æ—¥æœ¬èª: {len(ja_vocab)}å€‹")
        print(f"  è‹±èª: {len(en_vocab)}å€‹")
    
    print(f"âœ… åˆè¨ˆ {len(vocabulary)}å€‹ã®èªå½™ã‚’æŠ½å‡º")
    
    if len(vocabulary) >= 30:
        print("ğŸ‰ æˆåŠŸï¼30å€‹ä»¥ä¸Šã®èªå½™ã‚’æŠ½å‡ºã—ã¾ã—ãŸï¼")
    
    # ä¸Šä½5å€‹ã‚’è¡¨ç¤º
    print("\næŠ½å‡ºã•ã‚ŒãŸèªå½™ï¼ˆä¸Šä½5å€‹ï¼‰:")
    for i, vocab in enumerate(vocabulary[:5]):
        expr = vocab.get('expression', '')
        meaning = vocab.get('meaning', '')
        vocab_type = vocab.get('type', '?')
        
        if meaning:
            print(f"  {i+1}. {expr} â†’ {meaning} (ã‚¿ã‚¤ãƒ—: {vocab_type})")
        else:
            print(f"  {i+1}. {expr} (ã‚¿ã‚¤ãƒ—: {vocab_type})")

async def main():
    # å¼•æ•°è§£æ
    parser = argparse.ArgumentParser(description='YouTubeå­—å¹•ã‹ã‚‰NLPèªå½™æŠ½å‡ºãƒ†ã‚¹ãƒˆ')
    parser.add_argument('video_id', nargs='?', help='YouTubeå‹•ç”»IDï¼ˆçœç•¥æ™‚ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰')
    parser.add_argument('--lang', choices=['ja', 'en', 'auto'], default='auto',
                        help='è¨€èªæŒ‡å®š: ja=æ—¥æœ¬èª, en=è‹±èª, auto=è‡ªå‹•åˆ¤å®šï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰')
    args = parser.parse_args()
    
    print("ã‚·ãƒ³ãƒ—ãƒ«YouTubeãƒ†ã‚¹ãƒˆ")
    print("=" * 50)
    
    # å‹•ç”»IDã®æ±ºå®š
    if args.video_id:
        video_id = args.video_id
        print(f"æŒ‡å®šå‹•ç”»ID: {video_id}")
    else:
        video_id = get_test_video()
        print(f"ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå‹•ç”»: {WORKING_VIDEO_IDS[video_id]['title']}")
    
    # è¨€èªè¨­å®š
    force_lang = None if args.lang == 'auto' else args.lang
    if force_lang:
        print(f"è¨€èªãƒ¢ãƒ¼ãƒ‰: {force_lang}")
    else:
        print("è¨€èªãƒ¢ãƒ¼ãƒ‰: è‡ªå‹•åˆ¤å®š")
    
    # YouTubeå­—å¹•ãƒ†ã‚¹ãƒˆ
    success, transcript, detected_lang = test_youtube_direct(video_id, force_lang)
    
    if success:
        # NLPæŠ½å‡ºãƒ†ã‚¹ãƒˆ
        await test_nlp_extraction(transcript, detected_lang)

if __name__ == "__main__":
    print("ä½¿ã„æ–¹:")
    print("  python test_youtube_simple.py                      # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå‹•ç”»ã§ãƒ†ã‚¹ãƒˆ")
    print("  python test_youtube_simple.py VIDEO_ID             # ç‰¹å®šã®å‹•ç”»ã§ãƒ†ã‚¹ãƒˆ")
    print("  python test_youtube_simple.py VIDEO_ID --lang=ja   # æ—¥æœ¬èªå¼·åˆ¶")
    print("  python test_youtube_simple.py VIDEO_ID --lang=en   # è‹±èªå¼·åˆ¶")
    print("  python test_youtube_simple.py VIDEO_ID --lang=auto # è‡ªå‹•åˆ¤å®šï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰")
    print()
    
    asyncio.run(main())